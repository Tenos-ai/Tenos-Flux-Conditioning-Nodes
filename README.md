# Tenosâ€¯Fluxâ€¯Conditioningâ€¯Nodes ğŸš€

Custom **ComfyUI** nodes that superâ€‘charge [FluxDev](https://github.com/huggingface/diffusers?tab=readme-ov-file#the-flux-scheduler)â€‘style diffusion workflows.  
If â€œ_prompt engineering_â€ is your Katana, these nodes are the enchanted runes you carve into the blade to make it slice *cleaner, faster, smarter*.

---

## âœ¨ Why you might actually care

* **Layerâ€‘aware conditioning** â€“ target _specific_ Flux blocks (encoder, base, decoder, out) with perâ€‘layer multipliers  
* **Blend, add, or spatially concat** two completely different prompt stacks without losing context  
* **Builtâ€‘in sanity checks & tensor normalization** so you stop exploding your VRAM (and your temperament)  
* **Verbose summaries** pushed back to the ComfyUI frontâ€‘end via `PromptServer` â€“ know exactly what each node did in plain English (and a dash of snark)  
* Designed for **advanced LoRA / CLIPâ€‘T5 workflows** where you juggle dozens of conditioning tensors like a caffeinated circus act

_Node list and microâ€‘pitch below was autoâ€‘extracted from the source ğŸ“œ_ :contentReference[oaicite:0]{index=0}

| Node | I/O | Elevatorâ€¯Pitch |
|------|-----|---------------|
| **`TenosaiFluxConditioningApply`** | conditioning â†’ layered conditioning | Apply perâ€‘block strength multipliers to **one** conditioning list. |
| **`TenosaiFluxConditioningBlend`** | cond1 + cond2 â†’ layered conditioning | Blend two conditioning stacks **per block** with independent ratios. |
| **`TenosaiFluxConditioningSummedBlend`** | cond1 + cond2 â†’ single conditioning | Same as above, but outputs a _single_ summed tensor (keeps things slim). |
| **`TenosaiFluxConditioningAddScaledSum`** | cond1 + cond2 â†’ single conditioning | Scale cond2 per block, sum it, add onto total cond1. Think â€œadd a spicy toppingâ€. |
| **`TenosaiFluxConditioningSpatialWeightedConcat`** | cond1 + cond2 â†’ single conditioning | Concatenate cond1 & scaledâ€‘cond2 along the **sequence dimension** for spatial hacks. |

---

## ğŸ›  Installation

```bash
# 1. Clone (or submodule) into your ComfyUI custom-nodes folder
git clone https://github.com/YourUsername/tenos-flux-conditioning-nodes.git \
      ~/ComfyUI/custom_nodes/TenosFluxConditioning

# 2. (Optional) Create a fresh venv & install PyTorch if you somehow skipped that step ğŸ¤¨

# 3. Fire up ComfyUI and look for the â€œTenos.ai/Conditioningâ€ category.


> **Requires**:
>
> * PyTorch 2.1+ (CUDA or ROCm)
> * ComfyUI (latest main branch)
> * A model/scheduler that actually uses Flux blocks (e.g. *FluxDev* or similar)

---

## ğŸš¦ Quickâ€‘Start

1. **Load your prompts** using whatever tokenizer node floats your boat.
2. **Drag in** `TenosaiFluxConditioningApply` and connect your conditioning.
3. Dial in block multipliers (e.g. `encoder = 0.8`, `base = 1.2`, etc.).
4. Feed the output straight into your Fluxâ€‘compatible sampler.
5. Profit.
```
### Example flow (pseudoâ€‘graph)

```
CLIPTextEncode  â†’  TenosaiFluxConditioningApply  â†’  FluxSampler
                              â†‘
               Adjust multipliers per block in UI
```

---

## ğŸ“š Detailed Docs

* Each node has **tooltips** on every slider/checkbox â€“ hover like itâ€™s 1999.
* Output strings are accessible in ComfyUIâ€™s â€œimpactâ€‘nodeâ€‘feedbackâ€ panel; copyâ€‘paste for debugging.
* Shapes are automatically padded to the max sequence length across inputs. No more shape mismatches.
